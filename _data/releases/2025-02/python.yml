entries:
- Name: azure-search-documents
  Version: 11.6.0b9
  DisplayName: Azure AI Search
  ServiceName: Search
  VersionType: Beta
  Hidden: false
  ChangelogUrl: https://github.com/Azure/azure-sdk-for-python/tree/azure-search-documents_11.6.0b9/sdk/search/azure-search-documents/CHANGELOG.md
  ChangelogContent: |-
    #### Bugs Fixed

    - Exposed `@search.document_debug_info` in the search results.
- Name: azure-monitor-opentelemetry-exporter
  Version: 1.0.0b33
  DisplayName: OpenTelemetry Exporter
  ServiceName: Monitor
  VersionType: Beta
  Hidden: false
  ChangelogUrl: https://github.com/Azure/azure-sdk-for-python/tree/azure-monitor-opentelemetry-exporter_1.0.0b33/sdk/monitor/azure-monitor-opentelemetry-exporter/CHANGELOG.md
  ChangelogContent: |-
    #### Bugs Fixed

    - Detect live metrics usage during runtime in addition to on startup
    ([#37694](https://github.com/Azure/azure-sdk-for-python/pull/37694))
    - Remove status code `206` from retry code + only count batch level for statsbeat
    ([#38647](https://github.com/Azure/azure-sdk-for-python/pull/38647))

    #### Features Added

    - Implement live metrics filtering for metrics
    ([#37998](https://github.com/Azure/azure-sdk-for-python/pull/37998))
    - Add applying filter/validating filter logic to live metrics filtering
    ([#38451](https://github.com/Azure/azure-sdk-for-python/pull/38451))
    - Implement live metrics filtering for docs
    ([#38925](https://github.com/Azure/azure-sdk-for-python/pull/38925))
    - Implement live metrics + filtering for span event exceptions
    ([#39168](https://github.com/Azure/azure-sdk-for-python/pull/39168))
- Name: azure-monitor-query
  Version: 1.4.1
  DisplayName: Monitor Query
  ServiceName: Monitor
  VersionType: Patch
  Hidden: false
  ChangelogUrl: https://github.com/Azure/azure-sdk-for-python/tree/azure-monitor-query_1.4.1/sdk/monitor/azure-monitor-query/CHANGELOG.md
  ChangelogContent: |-
    #### Other Changes

    - Internal updates for linting and typing improvements.
- Name: azure-ai-inference
  Version: 1.0.0b7
  DisplayName: AI Model Inference
  ServiceName: Cognitive Services
  VersionType: Beta
  Hidden: false
  ChangelogUrl: https://github.com/Azure/azure-sdk-for-python/tree/azure-ai-inference_1.0.0b7/sdk/ai/azure-ai-inference/CHANGELOG.md
  ChangelogContent: |-
    #### Bugs Fixed

    * Fix a bug that would cause an error when tracing was enabled and azure-core-tracing-opentelemetry was not installed and asynchronous chat completion was used.
    * Enforce distinct timestamps on prompt and completion tracing events to preserve the order for chat history.

    #### Breaking Changes

    * If you previously configured your `ChatCompletionClient.complete()` call to output JSON format without a scheme, you have this in your code: `response_format=ChatCompletionsResponseFormatJSON()`. To maintain the same functionality, replace this with `response_format="json-object"`. We however recommend that you now switch to output JSON format with a provided schema if your AI model supports it: `response_format=JsonSchemaFormat(...)`.

    #### Features Added

    * Added a client for Image Embeddings, named `ImageEmbeddingsClient`. See package README.md and new samples.
    * Added support for Chat Completions response message in JSON format that adheres to a given JSON schema. Also known
    as "structured output". See new samples `sample_chat_completions_with_structured_output.py` and
    `sample_chat_completions_with_structured_output_pydantic.py`.
    * Made input argument `content` a positional argument (in addition to keyword argument), in the constructors of
    `UserMessage`, `SystemMessage`, `AssistantMessage` and `ToolMessage`. For example, you no longer need to write
    `UserMessage(content="my message")`. Simply write `UserMessage("my message")`. All samples were updated accordingly.

